What is kubernetes?
Kubernetes is a portable, extensible, open-source platform for managing workloads.
It is a managed, production-ready environment for deploying containerized applications.
It is a container orchestrator
Kubernetes is a system for automating deployment, scheduling and scaling (container instances) of containerized applications

Application containerization - OS level virtualization to deploy and run distributed application.
Multiple isolated applications or services run on a single host and access the same OS krnel

How it works? - include the runtime components (image)

Container engine - deploying images on host

The oldest way was applications on host (entangling with host OS and infrastructure)

The older way(VMs) was heavyweight, non-portable and relies on OS package manager

The new way (containers) is small, fast and portable across clouds and OS distributions.

Benefits
1. Efficiency for memory, CPU and storage.
2. Portability.
Drawbacks
1.Lack of isolation from core OS
2. No protection or lack of security

Kubernetes vs Docker (Swarm)
Kubernetes is a container orchestration solution.
Orchestration - execution of a defined workflow

Kubernetes, Docker Swarm, Mesos, Titus

Kubernetes provides a container-centric management environment
Platform as a Service(PaaS) - AWS Elastic Beanstalk, Microsoft Azure, Heroku


Features provided (container level) - deployment, scaling, load balancing, logging, monitoring
Supported workloads - stateless, stateful, data-processing
(CI/CD) Continuous Integration, Delivery and Deployment
Features not provided (application lvel) - middleware, data processing frameworks, databases, caches, cluster storage systems

Kubernetes means pilot, governor    K8s

Master components - control plane, making global decisions, detect and respond to cluster events
1. kube-apiserver - front-end for control plane
2. etcd - key value store for all cluster data
3. kube-scheduler - watches newly created pods and selects a node for them to run on
4. kube-controller-manager - runs controllers. controllers are compiled together and run as a single process
	Types of controllers include -
		i) Node controller
		ii) Replication controller
		iii) Endpoints controller
		iv) Service account & token controllers
5. cloud-controller-manager - runs controllers that interact with underlying cloud provider

containers -> pods -> nodes -> cluster -> master components

Pods - container for containers. Inside a pod, containers share same resources and local network. They can communicate but they still maintain isolation. At a time, replicas of your pod should be running to allow load balancing, failure resistance

Node - Smallest unit of computing hardware. Simply viewing each machine as a set of CPU and RAM resources
Node COmponents - 
1. kubelet - makes sure that containers run inside a pod
2. kube-proxy - enables k8s service abstraction by maintaining network rules and connection forwarding
3. Container Runtime

Cluster - nodes pool their resources together to make a big powerful machine. It intelligently distributes work to individual nodes

Persistent - plugging cloud drives or external hard disk to the cluster to store data permanently

1. Install Google Cloud SDk
2. Kubernetes cmd - gcloud components install kubectl
3. Install Docker or Docker Toolbox
4. Install git (git-scm.com)

1. git clone <url>
2. cd <dir>
3. gcloud auth configure-docker (use once only)

Step 1 -> Build docker container image

4. docker build -t name:tag
docker build -t gcr.io/k8stest2-223806/hello-app:v1 .

 

5. docker images

Step 2 -> Upload the container image to GCR (gcr means google container registry)

docker push gcr.io/k8stest2-223806/hello-app:v1

Step 3 -> Create a container cluster
gcloud container clusters create hello-cluster --num-nodes=3 --zone=asia-south1-a

gcloud compute instances list

((gcloud container clusters get-credentials hello-cluster)) 

gcloud compute regions list
gcloud compute zones list

Step 4 -> Deploy our application

kubectl run hello-web2 --image=gcr.io/k8stest2-223806/hello-app:v1 --port 8080
(run <-> create deployment) Deployment manages replicas of our application, schedules them to run on nodes
kubectl get pods


Step 5-> Exposing the application on internet

kubectl expose deployment hello-web2 --type=LoadBalancer --port 80 --target-port 8080
(expose <-> create service) Service providing networking and IP support to our appn's pods

kubectl get service

Open browser -> http://<external-ip>

Step 6 -> Scale up our application

kubectl scale deployment hello-web2 --replicas=3

kubectl get deployment hello-web2

kubectl get pods

(scale command adjusts capacity of our application. LoadBalancer routes traffic to new replicas immediately

Step 7 -> Deploy a new version of your app

kubectl set image <type>/<name> name=new image
kubectl set image deployment/hello-web2 hello-web2=gcr.io/k8stest2-223806/hello-app:v2

Open browser -> http://<external-ip>

Step 8 -> Cleaning up

i) Delete the service
kubectl delete service hello-web2

ii) Verifying that LoadBalancer (service) has been deleted
gcloud compute forwarding-rules list

iii)Delete the container cluster
gcloud container clusters delete hello-cluster --zone=asia-south1-a

Misc commands -
1. gcloud config set project k8stest2-223806
2. gcloud config set compute/zone us-central1-b
3. Run your container locally
	docker run --rm -p 8080:8080 gcr.io/k8stest2-223806/hello-app:v1
	then	
	Preview on port 8080 button
	or
	open a new shell window -> curl http://localhost:8080


K8s deployment strategies
1. Recreate -> Terminate the old version and release the new one
	Best for development environment
Pro : Application state is entirely renewed
Con : Downtime that depends on both shutdown and boot duration of the application




spec:
	replicas:3
	strategy:
		type:Recreate





2. Ramped -> Release a new version in a rolling update fashion, one after the other
	Best for slow rollout
Pro:Version is released slowly
Convenient for stateful applications so that they can handle rebalancing of data
Con:Rollout/rollback can take some time
No control over traffic



spec:
	strategy:
		type:RoliingUpdate
		rollingUpdate:
			maxSurge:2    #how many pods we can add at a time
			maxUnavailable:0 



3. Blue/green -> Release a new version alongside the older version and then switch traffic
	Best to avoid versioning issues
Pro:Version is released instantly
Change the entire cluster state in a go
Con:Requires the double resources
Proper testing should be done before switching the traffic
Handling stateful applications can be hard



selector:
	version: v2.0.0






4. Canary -> Release a new version to a subset of users, then we proceed to a full rollout
	Best for consumer testing
	HAproxy, Linkerd



spec:
	replicas:3



spec:
	replicas:1




5. A/B testing -> Release a new version to a subset of users but in a precise way(using Http headers and cookies). A/B testing is really a technique for business decisions based on statistics. Istio
Pro: Several versions run in parallel
Con:You have to set up additional tools
Hard to troubleshoot



route:
-tags:
	version:v1.0.0
	weight:90
-tags:
	version:v2.0.0
	weight:10



Common issues:
Pods in Pending, CrashLoopBackOff, Waiting, ErrImagePull
non-responsive pods containers
Difficulty in finding external IP

Pod status is Pending, CrashLoopBackOff
Typically because of insufficent CPU or memory resources or absence of volume provider
kubectl get pods -> Show the Pod_uid
kubectl describe pod pod_uid

Pod status show ErrImagePull, ImagePullBackOff
kubectl get pods
kubectl describe pod pod_uid
docker pull images


Unable to find your nodes
kubectl get nodes -> server doesnt have a resource
Occurs because authentication credentials are not correct

Difficulty in finding external IP
minikube ip
kubectl get nodes -o yaml


Pod is running but not responding
Occurs because of incorrect config or insufficient storage
ps
Status  Restarts  Ready


Kubernetes with KOPS on AWS

WSL -> Windows Subsytem for Linux

Prerequisite for Windows : Install Ubuntu 

Step 1 -> Create an AWS account (www.aws.amazon.com/free)

Step 2 -> Install python 
	sudo apt-get install python2.7

Step 3 -> Install pip
	sudo apt-get install python-pip
	If error comes -> (sudo apt-get update && sudo apt-get -y update) then use (sudo apt-get install python-pip)
	pip -V

Step 4 -> Install AWS CLI
	pip install awscli --upgrade --user
	aws --version

	if error comes -> which python
			ls -al /usr/bin/python
			ls -a    				(.local, .profile)
			export PATH=~/.local/bin
			source ~/.profile

	aws --version

Step 5 -> Configuration
	i) Create a new user on IAM Management Console
	ii) Give permissions -
		1. AmazonEC2FullAccess
		2. AmazonRoute53FullAccess
		3. AmazonS3FullAccess
		4. AmazonVPCFullAccess
		5. IAMFullAccess

	aws configure
	AWS Access Key ID [none]: AKIAJM5XLPU4JYFUVVFA
	AWS Secret Access Key [none]: ***********************
	Default region name [none]:us-east-2
	Default output format [None]:

Step 6 -> Create an S3 bucket
	aws s3api create-bucket --bucket anmoll-kops-state-store --region=us-west-2 --create-bucket-con
	figuration LocationConstraint=us-west-2

Step 7 -> Allow versioning of our bucket
	aws s3api put-bucket-versioning --bucket anmoll-kops-state-store --versioning-	configuration Status=Enabled

Step 8 optional -> Store our cluster name as well as bucket name locally
	export KOPS_CLUSTER_NAME=anmoll.k8s.local
	export KOPS_STATE_STORE=s3://anmoll-kops-state-store

Step 9 -> Create config file for cluster
	kops create cluster --node-count=2 --node-size=t2.medium --zones=us-east-1a --name=${KOPS_CLUSTER_NAME} 	--ssh-public-key {key} --cloud="aws"
	kops edit cluster --name=${KOPS_CLUSTER_NAME} 
	(It will open vi editor, to exit vi editor press Esc then :q! then press Enter)


To create sshkey -> kops create secret ssh-key {key}
			OR
		ssh-keygen

For help regarding clusters  -> kops create cluster --help


Step 10 -> Create the cluster
	kops update cluster --name=${KOPS_CLUSTER_NAME} --yes
	kops validate cluster

Step 11 -> deploy Kubernetes dashboard (web ui)
	kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml

Install kubectl
kubectl cluster-info
kubectl cluster-info dump

kops get secrets kube --type secret -oplaintext       //to extract password from kubernetes for dashboard
kops get secrets admin --type secret -oplaintext      //to extract secret token
kubectl cluster-info


kubectl proxy
Open the browser -> http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy
Userid as admin


Components of Cloud Controller Manager

1. Cloud-dependent controller loops that have been taken away from KCM
		Node controller
		Route controller
		Service controller
		PersistentVolumeLabels controller

	Node Controller
	1. Initialize a node with cloud specific zones/ regions and cloud-specific instance types such as type, 	size
	2. Obtain the node's ip adresses and hostname
	3. If node becomes unresponsive, check the cloud whether node has been deleted or some other error 	occured

	Route controller
	It is responsible for configuring routes in the cloud (containers running on different nodes but from 	same cluster can talk to each other

	Service Controller
	It is responsible for listening to events - create, update, delete.
	It configures cloud LoadBalancer

	PersistentVolumeLabels controller
	Automatically applies labels on volumes

2. kubelet

Prior to CCM, kubelet was responsible for Initialize a node with cloud specific zones/ regions and cloud-specific instance types such as type, 	size


3. kube-apiserver
Was responsible for PersistentVolumeLabels controller






